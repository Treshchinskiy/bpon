{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential - класс последовательности слоев в нейронной сети \n",
    "\n",
    "Dense - класс полносвязного/линейного слоя, все нейроны связаны \n",
    "друг с другом\n",
    "\n",
    "units=1 - количество нейронов в слое(здесь 1)\n",
    "\n",
    "input_shape=(1,) - входная размерность обьекта(у нас только один вход)\n",
    "\n",
    "activation='relu' - функция активации, которая добавляет в слой\n",
    "нелинейности(именно из-за нее мы получаем более сложные результаты)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "model1=Sequential([\n",
    "    Dense(1,input_shape=(1,),activation='relu')\n",
    "]) #здесь мы закладываем полносвязный слой из 1 нейрона и 1 вход\n",
    "#также для конкретного слоя можно задать свою функцию активации\n",
    "\n",
    "model1.summary() #резюме нашей модели\n",
    "#видим один слой dense_1, также выходная форма наша вектора с\n",
    "#этого слоя 1 значение(из-за input_shape) и здесь у нас есть\n",
    "#2 обучаемых параметра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.32573688]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_weights() #здесь те самые параметры\n",
    "#первый это вес при признаке и смещение это второй параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.6241963]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(10) #зафксировали веса\n",
    "\n",
    "model=Sequential([Dense(1,input_shape=(1,),activation='relu')])\n",
    "\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[1],[3],[2],[10],[4],[7],[8]])\n",
    "y=np.array([[3,9,6,30,12,21,24]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотим создать нейронную сеть чтобы она поняла как из массива X\n",
    "получился массив y\n",
    "\n",
    "Нам нужен один вход и один выход и один выход(число заходи умножается на 3 и выходит)\n",
    "\n",
    "то есть нам нужен один слой из одного нейрона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_62 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(1,input_shape=(1,),activation='linear')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.7953398]], dtype=float32), array([0.], dtype=float32))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1,w0=model.get_weights()\n",
    "w1,w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.7953398]], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[:1])#предсказание получается 0.03 \n",
    "\n",
    "#получили путем сложения w1*X[:1]+w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.79533982]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.activations import linear\n",
    "linear(w1*X[:1]+w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что именно мы здесь оптимизруем\n",
    "\n",
    "у нас задача здесь регрессии, поэтому на лучше оптимизировать MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='mse',metrics='mae')\n",
    "#оптимизатор - стохастический градиентный спуск\n",
    "#mse - то что именно мы оптимизируем\n",
    "#можно в метриках дополнительно указать что мы хотим чтобы высчитывалось\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 500.0456 - mae: 18.9767\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 42.4752 - mae: 5.4219\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6746 - mae: 1.5026\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3837 - mae: 0.4808\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1038 - mae: 0.2964\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0793 - mae: 0.2548\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0765 - mae: 0.2418\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0755 - mae: 0.2371\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0746 - mae: 0.2348\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0738 - mae: 0.2333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0730 - mae: 0.2319\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0722 - mae: 0.2306\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0714 - mae: 0.2293\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0706 - mae: 0.2281\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0699 - mae: 0.2268\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0691 - mae: 0.2256\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0684 - mae: 0.2243\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0676 - mae: 0.2231\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0669 - mae: 0.2219\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0661 - mae: 0.2207\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0654 - mae: 0.2195\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.2183\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0640 - mae: 0.2171\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0633 - mae: 0.2159\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0626 - mae: 0.2147\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0619 - mae: 0.2135\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0612 - mae: 0.2123\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0606 - mae: 0.2112\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0599 - mae: 0.2100\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0593 - mae: 0.2089\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0586 - mae: 0.2077\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0580 - mae: 0.2066\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0573 - mae: 0.2055\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0567 - mae: 0.2043\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0561 - mae: 0.2032\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0555 - mae: 0.2021\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0549 - mae: 0.2010\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0543 - mae: 0.1999\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0537 - mae: 0.1988\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0531 - mae: 0.1977\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0525 - mae: 0.1966\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0519 - mae: 0.1955\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0514 - mae: 0.1945\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0508 - mae: 0.1934\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0502 - mae: 0.1923\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 0.1913\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0492 - mae: 0.1902\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0486 - mae: 0.1892\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0481 - mae: 0.1882\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0476 - mae: 0.1871\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0470 - mae: 0.1861\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0465 - mae: 0.1851\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0460 - mae: 0.1841\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0455 - mae: 0.1831\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0450 - mae: 0.1820\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0445 - mae: 0.1811\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0440 - mae: 0.1801\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0436 - mae: 0.1791\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0431 - mae: 0.1781\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0426 - mae: 0.1771\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0421 - mae: 0.1761\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0417 - mae: 0.1752\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0412 - mae: 0.1742\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0408 - mae: 0.1733\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0403 - mae: 0.1723\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0399 - mae: 0.1714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0394 - mae: 0.1704\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0390 - mae: 0.1695\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0386 - mae: 0.1686\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0382 - mae: 0.1676\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0378 - mae: 0.1667\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0373 - mae: 0.1658\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0369 - mae: 0.1649\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0365 - mae: 0.1640\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0361 - mae: 0.1631\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1622\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0353 - mae: 0.1613\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0350 - mae: 0.1604\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0346 - mae: 0.1595\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0342 - mae: 0.1587\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0338 - mae: 0.1578\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0335 - mae: 0.1569\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0331 - mae: 0.1561\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0327 - mae: 0.1552\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1544\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0320 - mae: 0.1535\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0317 - mae: 0.1527\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.1518\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0310 - mae: 0.1510\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0306 - mae: 0.1502\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1494\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0300 - mae: 0.1485\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0296 - mae: 0.1477\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0293 - mae: 0.1469\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0290 - mae: 0.1461\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0287 - mae: 0.1453\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0284 - mae: 0.1445\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1437\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0277 - mae: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0274 - mae: 0.1422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f9460c7dd0>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100) #100 - сколько раз наша модель пробежится\n",
    "#по этим данным\n",
    "#каждый раз она будет уменьшать mse в наших вычислениях\n",
    "#loss - то что мы оптимизируем(функция потерь)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[[ 15.085363]\n",
      " [-26.281654]]\n"
     ]
    }
   ],
   "source": [
    "user_inp1,user_inp2=5,-9\n",
    "print(model.predict(np.array([[user_inp1],[user_inp2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.954787]], dtype=float32), array([0.3114285], dtype=float32)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [30],\n",
       "       [12],\n",
       "       [21],\n",
       "       [24]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'true':np.squeeze(y),\n",
    "    'pred': np.squeeze(model.predict(X))\n",
    "})\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.random.randint(1,10,size=50)\n",
    "X2=np.random.randint(1,10,size=50)\n",
    "\n",
    "y=X1+X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.vstack([X1,X2]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y=y[None]\n",
    "y=y.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т к сети - куча маленьких линейных регрессий, то им нужно масшабирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms=MinMaxScaler()\n",
    "X_norm=mms.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим сеть их 2 слоев, первый слой из 3 нейронов и выходной слой из 1 нейрона\n",
    "\n",
    "Оба числа будут заходить? в каждый из нейронов первого слоя\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(3,input_shape=(2,),activation='linear'), # 2 символа на вход и производиться 3 сигнала(нейрона из них)\n",
    "    Dense(1,activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_63 (Dense)            (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13 (52.00 Byte)\n",
      "Trainable params: 13 (52.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #output Shape(3 нерона и 1 нейрон)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество весов для одного нейрона равно 2, так как \n",
    "2 входа поступает, а вдобавок у каждого нейрона есть смещение\n",
    "\n",
    "А второй слой ждет на вход 3 сигналов + смещение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.07934737,  0.85043   , -0.47516358],\n",
       "        [-0.81244254, -0.52024883, -0.27658635]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[0.7794601 ],\n",
       "        [0.4441092 ],\n",
       "        [0.38089204]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() #тут у нас веса по слоям\n",
    "# первые два array это просто веса для наших чисел(первый)\n",
    "#и для смещений(второй) дальше по такой же схеме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#возьмем для оптимизации MSE\n",
    "#И снова используем sgd\n",
    "\n",
    "model.compile(optimizer='sgd',loss='mse',metrics='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 16ms/step - loss: 129.1708 - mae: 10.4244\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 107.0173 - mae: 9.3788\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 85.8050 - mae: 8.2682\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 58.6007 - mae: 6.6603\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 30.1195 - mae: 4.7535\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 12.2211 - mae: 2.9780\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.2306 - mae: 2.2937\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 6.3234 - mae: 2.1269\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 5.8716 - mae: 2.0501\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5623 - mae: 2.0003\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.2268 - mae: 1.9318\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.9269 - mae: 1.8776\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.6263 - mae: 1.8274\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.4018 - mae: 1.7758\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1303 - mae: 1.7138\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 3.9441 - mae: 1.6819\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.6258 - mae: 1.6199\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4517 - mae: 1.5720\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2223 - mae: 1.5306\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9578 - mae: 1.4699\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7508 - mae: 1.4165\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.6015 - mae: 1.3747\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.4147 - mae: 1.3316\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3026 - mae: 1.2905\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.1384 - mae: 1.2547\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.9849 - mae: 1.1971\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8695 - mae: 1.1701\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.7238 - mae: 1.1111\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5980 - mae: 1.0820\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4928 - mae: 1.0430\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3980 - mae: 1.0133\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.3004 - mae: 0.9742\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2072 - mae: 0.9334\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.1129 - mae: 0.9119\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0229 - mae: 0.8620\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9423 - mae: 0.8372\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8739 - mae: 0.8056\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8166 - mae: 0.7733\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7536 - mae: 0.7473\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6898 - mae: 0.7201\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6386 - mae: 0.6883\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5879 - mae: 0.6661\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5431 - mae: 0.6398\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4971 - mae: 0.6027\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4565 - mae: 0.5830\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4201 - mae: 0.5580\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3853 - mae: 0.5367\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3527 - mae: 0.5148\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3227 - mae: 0.4884\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2993 - mae: 0.4700\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.2741 - mae: 0.4536\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2528 - mae: 0.4377\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2316 - mae: 0.4109\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2117 - mae: 0.3943\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1956 - mae: 0.3791\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.1788 - mae: 0.3707\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1625 - mae: 0.3454\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.1476 - mae: 0.3346\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.1344 - mae: 0.3171\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1237 - mae: 0.3048\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1138 - mae: 0.2905\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.1044 - mae: 0.2784\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0952 - mae: 0.2702\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0874 - mae: 0.2582\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0805 - mae: 0.2486\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0736 - mae: 0.2354\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0701 - mae: 0.2316\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0632 - mae: 0.2132\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0569 - mae: 0.2087\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0529 - mae: 0.2014\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0482 - mae: 0.1888\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0442 - mae: 0.1832\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0410 - mae: 0.1762\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0379 - mae: 0.1714\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0347 - mae: 0.1648\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0316 - mae: 0.1544\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0288 - mae: 0.1473\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0275 - mae: 0.1446\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0259 - mae: 0.1409\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0239 - mae: 0.1377\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0215 - mae: 0.1300\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0192 - mae: 0.1226\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0174 - mae: 0.1163\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0157 - mae: 0.1112\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0142 - mae: 0.1039\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0131 - mae: 0.1000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0123 - mae: 0.0983\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0116 - mae: 0.0936\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0105 - mae: 0.0877\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0094 - mae: 0.0858\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0087 - mae: 0.0825\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0081 - mae: 0.0784\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0073 - mae: 0.0738\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0067 - mae: 0.0713\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0685\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0057 - mae: 0.0663\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0053 - mae: 0.0629\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0048 - mae: 0.0605\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0046 - mae: 0.0587\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0042 - mae: 0.0559\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0038 - mae: 0.0540\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0035 - mae: 0.0520\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0032 - mae: 0.0493\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0030 - mae: 0.0480\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0028 - mae: 0.0461\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0025 - mae: 0.0439\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0024 - mae: 0.0424\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0022 - mae: 0.0403\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0020 - mae: 0.0388\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0019 - mae: 0.0377\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0018 - mae: 0.0365\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0016 - mae: 0.0344\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0015 - mae: 0.0331\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0014 - mae: 0.0319\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0013 - mae: 0.0310\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0297\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0011 - mae: 0.0282\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 9.9735e-04 - mae: 0.0273\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 9.1277e-04 - mae: 0.0262\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 8.3775e-04 - mae: 0.0251\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 7.6985e-04 - mae: 0.0240\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 7.1124e-04 - mae: 0.0231\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 6.5515e-04 - mae: 0.0221\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 6.3515e-04 - mae: 0.0219\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.7549e-04 - mae: 0.0203\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 5.2021e-04 - mae: 0.0196\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 4.8019e-04 - mae: 0.0189\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 4.4426e-04 - mae: 0.0181\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 4.1311e-04 - mae: 0.0174\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.8617e-04 - mae: 0.0169\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 3.5616e-04 - mae: 0.0162\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 3.2821e-04 - mae: 0.0155\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.0257e-04 - mae: 0.0150\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.7682e-04 - mae: 0.0142\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.5792e-04 - mae: 0.0137\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.3791e-04 - mae: 0.0131\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.1877e-04 - mae: 0.0127\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.0233e-04 - mae: 0.0122\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8773e-04 - mae: 0.0117\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.7406e-04 - mae: 0.0113\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5957e-04 - mae: 0.0108\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4797e-04 - mae: 0.0104\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.3733e-04 - mae: 0.0100\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2854e-04 - mae: 0.0096\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.1865e-04 - mae: 0.0093\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0786e-04 - mae: 0.0089\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.9437e-05 - mae: 0.0085\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 9.1644e-05 - mae: 0.0081\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 8.6765e-05 - mae: 0.0080\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9389e-05 - mae: 0.0075\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.5216e-05 - mae: 0.0074\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.8139e-05 - mae: 0.0069\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2205e-05 - mae: 0.0067\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 5.9730e-05 - mae: 0.0065\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 5.4079e-05 - mae: 0.0063\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 5.0568e-05 - mae: 0.0060\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 4.6728e-05 - mae: 0.0057\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 4.2475e-05 - mae: 0.0056\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 3.8791e-05 - mae: 0.0053\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 3.5901e-05 - mae: 0.0051\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.3166e-05 - mae: 0.0049\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 3.0754e-05 - mae: 0.0047\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9440e-05 - mae: 0.0046\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.6664e-05 - mae: 0.0043\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4707e-05 - mae: 0.0042\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3167e-05 - mae: 0.0041\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.0807e-05 - mae: 0.0038\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.9031e-05 - mae: 0.0037\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.7650e-05 - mae: 0.0036\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6515e-05 - mae: 0.0034\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.5295e-05 - mae: 0.0033\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.4312e-05 - mae: 0.0032\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.3224e-05 - mae: 0.0031\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.2194e-05 - mae: 0.0029\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.1268e-05 - mae: 0.0028\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0756e-05 - mae: 0.0028\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 9.8091e-06 - mae: 0.0026\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 8.9831e-06 - mae: 0.0025\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 8.3332e-06 - mae: 0.0024\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 7.8224e-06 - mae: 0.0023\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.2382e-06 - mae: 0.0022\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.8105e-06 - mae: 0.0022\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 6.2454e-06 - mae: 0.0021\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 5.8353e-06 - mae: 0.0020\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.4012e-06 - mae: 0.0020\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 5.2377e-06 - mae: 0.0019\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 4.7091e-06 - mae: 0.0018\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.2717e-06 - mae: 0.0017\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9257e-06 - mae: 0.0017\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.6632e-06 - mae: 0.0016\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.3518e-06 - mae: 0.0015\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.0834e-06 - mae: 0.0015\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.9192e-06 - mae: 0.0014\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.6833e-06 - mae: 0.0014\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.4528e-06 - mae: 0.0013\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.2746e-06 - mae: 0.0013\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.1038e-06 - mae: 0.0012\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0940e-06 - mae: 0.0012\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8561e-06 - mae: 0.0012\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6620e-06 - mae: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f946166f90>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_norm,y,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.0011683],\n",
       "       [8.001767 ]], dtype=float32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X=[[4,2],\n",
    "        [6,2]]\n",
    "\n",
    "test_X=mms.transform(test_X)\n",
    "model.predict(np.array(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>14.999491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>16.999361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>16.999361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>12.002236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  true       pred\n",
       "0   7   8    15  14.999491\n",
       "1   2   3     5   5.000141\n",
       "2   8   9    17  16.999361\n",
       "3   8   9    17  16.999361\n",
       "4   9   3    12  12.002236"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'x1':X[:,0],\n",
    "    'x2':X[:,1],\n",
    "   'true' : np.squeeze(y),\n",
    "   'pred':np.squeeze(model.predict(X_norm))\n",
    "}).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data() \n",
    "\n",
    "X_train.shape,X_test.shape #28 на 28 пикселей картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(1,5,figsize=(15,10))\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i].imshow(X_train[i],cmap='gray')\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#возьмем только 0 и 1\n",
    "idxs=np.where((y_train==0) | (y_train==1))\n",
    "y_train=y_train[idxs] #берем целевые значения только по этим индексам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12665, 28, 28), (12665,))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2115, 28, 28), (2115,))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Тоже самое для теста\n",
    "idxs=np.where((y_test==0) | (y_test==1))\n",
    "y_test=y_test[idxs]\n",
    "X_test=X_test[idxs]\n",
    "\n",
    "X_test.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сейчас будем стандартизировать делением на наибольшое значение\n",
    "\n",
    "X_train=X_train/250.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас буде изменять вид целевого класса, так как сейчас она является лейблами 0 и 1, нам нужно преобразовать в бинапный вид\n",
    "\n",
    "Тем самым получим 2 столбика, где первый - является ли изображение\n",
    "0 классом, а второй - является ли изображение 1 классаом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, 1, 1], dtype=uint8),\n",
       " array([[1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical \n",
    "y_train_cat=to_categorical(y_train)\n",
    "y_test_cat=to_categorical(y_test)\n",
    "y_train[:5],y_train_cat[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А чтобы сделать еще легче, поменяем масшат изображений\n",
    "сделав масштаб меньше чем 28 на 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_resized=tf.image.resize(X_train[...,np.newaxis],(6,6))[...,0] #пиздец\n",
    "X_test_resized=tf.image.resize(X_test[...,np.newaxis],(6,6))[...,0]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,5,figsize=(15,10))\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i].imshow(X_train_resized[i],cmap='gray')\n",
    "    ax[i].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пока у нас картинки это величина двумерная так как 6 на 6 это матрица\n",
    "\n",
    "А наши полносвязные слови принимают только вектора, поэтому нужн преобразовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resized[0].numpy().flatten()\n",
    "X_train_resized[0].numpy().flatten().shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас будет 36 входов для каждого из наших пикселей\n",
    "\n",
    "И очевидно 2 выхода для бинарной классификации(каждый из выходных\n",
    "нейронов выдает вероятность принадлежности к определенному классу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 36)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 2)                 74        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74 (296.00 Byte)\n",
      "Trainable params: 74 (296.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "\n",
    "model=Sequential([\n",
    "    Flatten(input_shape=(6,6)), #?\n",
    "    Dense(2,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи классификации для метрики которую мы хотим оптимизировать\n",
    "не подойдет то что мы брали до этого, лучше взятбь бинарную\n",
    "кросс-энтропию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 4s 4ms/step - loss: 0.5842 - accuracy: 0.7355\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.4523 - accuracy: 0.9692\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.9793\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.3177 - accuracy: 0.9800\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2800 - accuracy: 0.9794\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2521 - accuracy: 0.9791\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2306 - accuracy: 0.9788\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2134 - accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.1994 - accuracy: 0.9793\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f945f1a690>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_resized,y_train_cat,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[[0.1172469 0.8649541]]\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_test_resized[:1])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax() #берем максимальную вероятность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'pred 1, true 1')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx=0\n",
    "plt.imshow(X_test_resized[idx])\n",
    "plt.title(f'pred {pred.argmax()}, true {y_test[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
